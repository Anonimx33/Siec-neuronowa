{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b03329b-39af-4e0b-befe-17ab196eaaa6",
   "metadata": {},
   "source": [
    "#Reading data\n",
    "https://github.com/ASaid7/MLP-from-Scratch/blob/master/multilayer%20perceptron.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b0c8062-a333-40d4-a7bf-0d1fd55804b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import import_ipynb\n",
    "import images_data\n",
    "from functools import partial\n",
    "\n",
    "import nbimporter\n",
    "from Layer import Layer\n",
    "\n",
    "PATH_TRAIN_IMAGES = \"data/train-images-idx3-ubyte\"\n",
    "PATH_TRAIN_LABELS = \"data/train-labels-idx1-ubyte\"\n",
    "\n",
    "PATH_TEST_IMAGES = \"data/t10k-images-idx3-ubyte\"\n",
    "PATH_TEST_LABELS = \"data/t10k-labels-idx1-ubyte\"\n",
    "\n",
    "COL_SIZE = 28\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51eac59-1a97-4d6a-a2cd-9b9941616367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do innego pliku\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def deriative_sigmoid(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "417ec320-d243-4fd1-b6a9-83c54493a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, list_of_numbers_of_neurons, learning_rate, activation, deriative):\n",
    "        self.number_of_neurons = list_of_numbers_of_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = []\n",
    "        self.erors = None\n",
    "        for index in range(1, len(list_of_numbers_of_neurons)):\n",
    "            layer = Layer(list_of_numbers_of_neurons[index], list_of_numbers_of_neurons[index - 1], activation, deriative)\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "\n",
    "    def feed_forward(self, inputs: np.array) -> np.array:\n",
    "        last_out = inputs.copy()\n",
    "        for index in range(len(self.layers)):\n",
    "            print(last_out.shape, self.layers[index].biases.shape, \"shape\", self.layers[index].number_of_neurons)\n",
    "            last_out = self.layers[index].activation(last_out)\n",
    "        return last_out\n",
    "    \n",
    "    \n",
    "    def feed_back(self, inputs: np.array, y: np.array):\n",
    "        result_from_network = self.feed_forward(inputs)\n",
    "        \n",
    "        last_layer = self.layers[-1]\n",
    "        cost_derivative = inputs - y #różnica między oczekiwanym a rzeczywistym\n",
    "        sigmoid_derivative = deriative_sigmoid(Network.last_layer.z) #z to whynik przed sigmoidą\n",
    "\n",
    "        errors = []\n",
    "        delta = cost_derivative * sigmoid_derivative \n",
    "        errors.insert(0, delta) #wrzucanie na początek listy\n",
    "\n",
    "        for layer in self.layers.reverse():\n",
    "            cost_derivative = np.dot(layer.weights.T, delta) # czemy Transpose\n",
    "            sigmoid_derivative = layer.deriative(layer.z)\n",
    "            delta = cost_derivative * sigmoid_derivative\n",
    "            errors.insert(0, delta)\n",
    "        return errors\n",
    "    \n",
    "    \n",
    "    def train(self, mini_batch):\n",
    "        delta_biases = [np.zeros(layer.biases.shape) for layer in self.layers]\n",
    "        delta_weights = [np.zeros(layer.weights.shape) for layer in self.layers]\n",
    "\n",
    "        for sample in mini_batch: # obrazek wektor wyjść\n",
    "            x, y = sample\n",
    "\n",
    "            errors = self.feed_back(x, y)\n",
    "            (\n",
    "                delta_weights_backprop,\n",
    "                delta_biases_backprop,\n",
    "            ) = self.get_delta_weights_and_biases_from_errors(x, errors)\n",
    "\n",
    "            for layer_index in range(len(self.layers)):\n",
    "                delta_biases[layer_index] += delta_biases_backprop[layer_index]\n",
    "                delta_weights[layer_index] += delta_weights_backprop[layer_index]\n",
    "#oco biega\n",
    "        for layer_index in range(len(self.layers)):\n",
    "            delta_biases[layer_index] *= 1.0 / len(mini_batch)\n",
    "            delta_biases[layer_index] *= self.learning_rate\n",
    "\n",
    "            delta_weights[layer_index] *= 1.0 / len(mini_batch)\n",
    "            delta_weights[layer_index] *= self.learning_rate\n",
    "\n",
    "        self.update_weights_and_biases(delta_weights, delta_biases)\n",
    "        \n",
    "\n",
    "    def get_delta_weights_and_biases_from_errors(self, inputs: np.array, errors):\n",
    "        to_change_biases = list()\n",
    "        to_change_weights = list()\n",
    "\n",
    "        for layer_index in range(len(self.layers) - 1, -1, -1):\n",
    "            delta = errors[layer_index]\n",
    "            to_change_biases.insert(0, delta.copy())\n",
    "\n",
    "            if layer_index == 0:\n",
    "                to_change_weights.insert(0, np.dot(delta, inputs.T))\n",
    "            else:\n",
    "                to_change_weights.insert(0, np.dot(delta, self.layers[layer_index - 1].a.T))\n",
    "\n",
    "        return to_change_weights, to_change_biases\n",
    "    \n",
    "\n",
    "    def update_weights_and_biases(\n",
    "        self, delta_weights, delta_biases):\n",
    "        \n",
    "        for index, layer in enumerate(self.layers):\n",
    "            layer.set_biases(layer.biases - delta_biases[index])\n",
    "            layer.set_weights(layer.weights - delta_weights[index])\n",
    "\n",
    "    def cost(self, y: np.array):\n",
    "        return 0.5 * (y - self.layers[-1].a) ** 2\n",
    "\n",
    "    def final_cost(self, y: np.array):\n",
    "        return sum(x for x in self.cost(y))\n",
    "\n",
    "\n",
    "    def dump_to_file(self, folder_name: str = \"model_w_b\"):\n",
    "        weights = np.array([layer.weights for layer in self.layers])\n",
    "        biases = np.array([layer.biases for layer in self.layers])\n",
    "        np.save(f'{folder_name}/weights.npy', weights)\n",
    "        np.save(f'{folder_name}/biases.npy', biases)\n",
    "\n",
    "    \n",
    "    def loss(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred)**2)\n",
    "    \n",
    "    def dloss(self, y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_true.size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3bc66bc-9d29-4ca2-9932-3ed405d24d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(images, labels):\n",
    "    network_input_size = images[0].flatten().size\n",
    "\n",
    "    return [\n",
    "        ((image.flatten() / 255).reshape((network_input_size, 1)), int(label))\n",
    "        for image, label in zip(images, labels)\n",
    "    ]\n",
    "\n",
    "def make_output(number: int):\n",
    "    n = np.zeros((10, 1))\n",
    "    n[number][0] = 1.0\n",
    "    return n\n",
    "\n",
    "def main():\n",
    "    # number of pixels in photo\n",
    "    train_images, train_labels = images_data.load_datasets() \n",
    "    network_input_size = train_images[0].flatten().size\n",
    "\n",
    "    # numbers in <0, 9>\n",
    "    network_output_size = 10\n",
    "\n",
    "    learning_rate = 0.1\n",
    "\n",
    "    network = Network([network_input_size, 5, network_output_size],\n",
    "                      0.1, sigmoid, deriative_sigmoid)\n",
    "\n",
    "    train_data = prepare_data(train_images, train_labels)\n",
    "    np.random.shuffle(train_data)\n",
    "\n",
    "    test_images, test_labels = images_data.load_datasets(set_name=\"test\") \n",
    "    test_data = prepare_data(test_images, test_labels)\n",
    "    np.random.shuffle(test_data)\n",
    "\n",
    "    number_of_epochs = 5\n",
    "    batch_size = 15\n",
    "\n",
    "  \n",
    "    for epoch in range(number_of_epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "\n",
    "        for i in range(0, len(train_data) - batch_size, batch_size):\n",
    "            mini_batch: List[Tuple[np.array, np.array]] = []\n",
    "\n",
    "            for _, number in enumerate(train_data[i: i + batch_size]):\n",
    "                pixels, number_label = number\n",
    "                results: np.array = make_output(number_label)\n",
    "                mini_batch.append((pixels, results))\n",
    "\n",
    "            network.train(mini_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02b27eab-39d0-4956-9fdd-ec7c8487334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "(784, 1) (784,) shape 784\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (784,10) and (784,1) not aligned: 10 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     results: np\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m make_output(number_label)\n\u001b[1;32m     47\u001b[0m     mini_batch\u001b[38;5;241m.\u001b[39mappend((pixels, results))\n\u001b[0;32m---> 49\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mNetwork.train\u001b[0;34m(self, mini_batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m mini_batch: \u001b[38;5;66;03m# obrazek wektor wyjść\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m sample\n\u001b[0;32m---> 46\u001b[0m     errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_back\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     (\n\u001b[1;32m     48\u001b[0m         delta_weights_backprop,\n\u001b[1;32m     49\u001b[0m         delta_biases_backprop,\n\u001b[1;32m     50\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_delta_weights_and_biases_from_errors(x, errors)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)):\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mNetwork.feed_back\u001b[0;34m(self, inputs, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_back\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: np\u001b[38;5;241m.\u001b[39marray, y: np\u001b[38;5;241m.\u001b[39marray):\n\u001b[0;32m---> 21\u001b[0m     result_from_network \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     last_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     24\u001b[0m     cost_derivative \u001b[38;5;241m=\u001b[39m inputs \u001b[38;5;241m-\u001b[39m y \u001b[38;5;66;03m#różnica między oczekiwanym a rzeczywistym\u001b[39;00m\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mNetwork.feed_forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(last_out\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[index]\u001b[38;5;241m.\u001b[39mbiases\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[index]\u001b[38;5;241m.\u001b[39mnumber_of_neurons)\n\u001b[0;32m---> 16\u001b[0m     last_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m last_out\n",
      "File \u001b[0;32m<string>:15\u001b[0m, in \u001b[0;36mactivation\u001b[0;34m(self, inputs)\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (784,10) and (784,1) not aligned: 10 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a736c0-9f0e-43db-8b8d-0c2e22b98c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637ca77-071b-409a-9d3c-75d6ce993c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9929026-66dc-40c4-8ab1-96bb05bd7f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neural_Network",
   "language": "python",
   "name": "neural_network"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
